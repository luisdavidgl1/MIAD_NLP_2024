{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales Recurrentes - LSTM\n",
    "\n",
    "En este notebook aprenderá a construir y a entrenar redes neuronales recurrentes (LSTM), usando la librería [Keras](https://keras.io/).\n",
    "\n",
    "Este notebook tiene una licencia de [Creative Commons Attribution-ShareAlike 3.0 Unported License](http://creativecommons.org/licenses/by-sa/3.0/deed.en_US)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones Generales\n",
    "\n",
    "Este notebook esta compuesto por dos secciones. En la primera secciónn, usted beberá construir y entrenar un modelo de random forest para predecir si una URL es phishing (fraudulento) o no. En la segunda parte, usará el mismo dataset pero beberá construir y entrenar una red neuronal recurrente para ver las ganancias en predicción. En el siguente paper puede conocer más detalles de la base y del problema: *A. Correa Bahnsen, E. C. Bohorquez, S. Villegas, J. Vargas, and F. A. Gonzalez, “Classifying phishing urls using recurrent neural networks,” in Electronic Crime Research (eCrime), 2017 APWG Symposium on. IEEE, 2017, pp. 1–8*. https://albahnsen.com/wp-content/uploads/2018/05/classifying-phishing-urls-using-recurrent-neural-networks_cameraready.pdf\n",
    "  \n",
    "Para realizar la actividad, solo siga las indicaciones asociadas a cada celda del notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar base de datos y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.subalipack.com/contact/images/sampl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://fasc.maximecapellot-gypsyjazz-ensemble....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://theotheragency.com/confirmer/confirmer-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://aaalandscaping.com/components/com_smart...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://paypal.com.confirm-key-21107316126168.s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  phishing\n",
       "0  http://www.subalipack.com/contact/images/sampl...         1\n",
       "1  http://fasc.maximecapellot-gypsyjazz-ensemble....         1\n",
       "2  http://theotheragency.com/confirmer/confirmer-...         1\n",
       "3  http://aaalandscaping.com/components/com_smart...         1\n",
       "4  http://paypal.com.confirm-key-21107316126168.s...         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/phishing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de texto (URLs) para crear variables predictoras\n",
    "\n",
    "# Creación de columnas binarias que indican si la URL contiene la palabra clave (keywords)\n",
    "keywords = ['https', 'login', '.php', '.html', '@', 'sign']\n",
    "for keyword in keywords:\n",
    "    data['keyword_' + keyword] = data.url.str.contains(keyword).astype(int)\n",
    "\n",
    "# Definición de la variable largo de la URL\n",
    "data['lenght'] = data.url.str.len() - 2\n",
    "\n",
    "# Definición de la variable largo del dominio de la URL\n",
    "domain = data.url.str.split('/', expand=True).iloc[:, 2]\n",
    "data['lenght_domain'] = domain.str.len()\n",
    "\n",
    "# Definición de la variable binaria que indica si es IP\n",
    "data['isIP'] = (domain.str.replace('.', '') * 1).str.isnumeric().astype(int)\n",
    "\n",
    "# Definicón de la variable cuenta de 'com' en la URL\n",
    "data['count_com'] = data.url.str.count('com')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de variables predictoras (X)\n",
    "X = data.drop(['url', 'phishing'], axis=1)\n",
    "# Definición de variable de interés (y)\n",
    "y = data.phishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y) en set de entrenamiento y test usandola función train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de modelo de clasificación Random Forest\n",
    "clf = RandomForestClassifier(n_jobs=-1, n_estimators=100)\n",
    "\n",
    "# Entrenamiento del modelo de clasificación Random Forest usando el set de entrenamiento\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicción del modelo de clasificación Random Forest usando el set de test\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Impresión del desempeño del modelo\n",
    "print((y_pred == y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Red Neuronal Recurrente - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\luis.gutierrez\\appdata\\local\\anaconda3\\envs\\miad\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\luis.gutierrez\\appdata\\local\\anaconda3\\envs\\miad\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\luis.gutierrez\\appdata\\local\\anaconda3\\envs\\miad\\lib\\site-packages (from keras) (1.26.3)\n",
      "Requirement already satisfied: rich in c:\\users\\luis.gutierrez\\appdata\\local\\anaconda3\\envs\\miad\\lib\\site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\luis.gutierrez\\appdata\\local\\anaconda3\\envs\\miad\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\luis.gutierrez\\appdata\\local\\anaconda3\\envs\\miad\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\luis.gutierrez\\appdata\\local\\anaconda3\\envs\\miad\\lib\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\luis.gutierrez\\appdata\\local\\anaconda3\\envs\\miad\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\luis.gutierrez\\appdata\\local\\anaconda3\\envs\\miad\\lib\\site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\luis.gutierrez\\appdata\\local\\anaconda3\\envs\\miad\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\luis.gutierrez\\appdata\\local\\anaconda3\\envs\\miad\\lib\\site-packages (from rich->keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\luis.gutierrez\\appdata\\local\\anaconda3\\envs\\miad\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from livelossplot import PlotLossesKeras\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L': 1,\n",
       " '2': 2,\n",
       " 'k': 3,\n",
       " 's': 4,\n",
       " 'ä': 5,\n",
       " '/': 6,\n",
       " \"'\": 7,\n",
       " '¬': 8,\n",
       " '&': 9,\n",
       " '5': 10,\n",
       " '(': 11,\n",
       " '3': 12,\n",
       " '~': 13,\n",
       " '@': 14,\n",
       " ']': 15,\n",
       " 'K': 16,\n",
       " 't': 17,\n",
       " 'T': 18,\n",
       " 'm': 19,\n",
       " 'H': 20,\n",
       " 'A': 21,\n",
       " 'p': 22,\n",
       " '$': 23,\n",
       " '*': 24,\n",
       " 'q': 25,\n",
       " 'B': 26,\n",
       " '[': 27,\n",
       " '_': 28,\n",
       " 'a': 29,\n",
       " '%': 30,\n",
       " '>': 31,\n",
       " 'e': 32,\n",
       " 'X': 33,\n",
       " 'M': 34,\n",
       " 'x': 35,\n",
       " ';': 36,\n",
       " '�': 37,\n",
       " 'ü': 38,\n",
       " '9': 39,\n",
       " '#': 40,\n",
       " '\\\\': 41,\n",
       " '8': 42,\n",
       " '\\n': 43,\n",
       " 'f': 44,\n",
       " 'G': 45,\n",
       " 'Q': 46,\n",
       " 'Y': 47,\n",
       " '^': 48,\n",
       " '?': 49,\n",
       " ':': 50,\n",
       " 'U': 51,\n",
       " 'F': 52,\n",
       " 'O': 53,\n",
       " '.': 54,\n",
       " 'N': 55,\n",
       " 'h': 56,\n",
       " 'b': 57,\n",
       " 'w': 58,\n",
       " '+': 59,\n",
       " 'o': 60,\n",
       " '|': 61,\n",
       " 'J': 62,\n",
       " 'E': 63,\n",
       " 'Z': 64,\n",
       " 'i': 65,\n",
       " '`': 66,\n",
       " '£': 67,\n",
       " '¢': 68,\n",
       " '0': 69,\n",
       " '6': 70,\n",
       " 'P': 71,\n",
       " 'D': 72,\n",
       " 'c': 73,\n",
       " '=': 74,\n",
       " '-': 75,\n",
       " 'd': 76,\n",
       " '!': 77,\n",
       " 'u': 78,\n",
       " 'y': 79,\n",
       " 'C': 80,\n",
       " 'v': 81,\n",
       " 'z': 82,\n",
       " '4': 83,\n",
       " 'g': 84,\n",
       " 'r': 85,\n",
       " 'I': 86,\n",
       " 'W': 87,\n",
       " ' ': 88,\n",
       " ')': 89,\n",
       " ',': 90,\n",
       " '1': 91,\n",
       " '<': 92,\n",
       " 'S': 93,\n",
       " '7': 94,\n",
       " 'V': 95,\n",
       " 'j': 96,\n",
       " 'R': 97,\n",
       " 'n': 98,\n",
       " 'l': 99}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocesamiento de texto (URLs) para crear variables predictoras\n",
    "X = data['url'].tolist()\n",
    "\n",
    "# Definición de vocabulario\n",
    "voc = set(''.join(X))\n",
    "vocabulary = {x: idx + 1 for idx, x in enumerate(set(voc))}\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición máximo largo de embedding\n",
    "max_url_len = 150\n",
    "\n",
    "# Codificación (embedding) de la URL con el vocabulario definido anteriormente\n",
    "X = [x[:max_url_len] for x in X]\n",
    "X = [[vocabulary[x1] for x1 in x if x1 in vocabulary.keys()] for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 32,  6, 43],\n",
       "       [ 0,  0,  0, ..., 17, 19, 43],\n",
       "       [ 0,  0,  0, ..., 12,  6, 43],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 19, 99, 43],\n",
       "       [ 0,  0,  0, ..., 12, 10, 43],\n",
       "       [ 0,  0,  0, ..., 69, 12, 43]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de embedding con el largo máximo definido anteriormente\n",
    "X_pad = sequence.pad_sequences(X, maxlen=max_url_len)\n",
    "X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X_pad) y variable de interés (y) en set de entrenamiento y test usando la función train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición red neuronal con la función Sequential()\n",
    "model = Sequential()\n",
    "\n",
    "# Definición de la capa embedding\n",
    "model.add(Embedding(len(vocabulary) + 1, 128, input_length=max_url_len))\n",
    "# Definición de la capa recurrente LSTM\n",
    "model.add(LSTM(32))\n",
    "# Definición de dropout para evitar overfitting\n",
    "model.add(Dropout(0.5))\n",
    "# Definición capa densa con función sigmoide para predicción binaria final\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Definición de función de perdida.\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "# Impresión de la arquitectura de la red neuronal\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento de la red neuronal usando el set de entrenamiento\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "          batch_size=128, epochs=10, verbose=1,\n",
    "          callbacks=[PlotLossesKeras()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción de la red neuronal usando el set de test\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.round(y_pred.flatten()).astype(int)\n",
    "\n",
    "# Impresión del desempeño de la red neuronal\n",
    "print((y_pred == y_test).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
